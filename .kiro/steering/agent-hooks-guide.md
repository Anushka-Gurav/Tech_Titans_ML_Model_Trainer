---
inclusion: always
---

# Agent Hooks Configuration Guide

This document provides pre-configured agent hooks for the ML Training Platform project to automate quality checks, environment validation, and development workflow consistency.

## Quick Setup Instructions

1. Open Command Palette in Kiro (`Ctrl+Shift+P` or `Cmd+Shift+P`)
2. Search for "Open Kiro Hook UI"
3. Create new hooks using the configurations below
4. Copy the exact trigger, action, and content for each hook

## Hook Configurations

### 1. Environment Check Hook

**Purpose**: Verify development environment before starting tasks
**Trigger**: On message send (when starting a task)
**Action**: Send message to agent

```
Hook Name: Environment Check
Trigger: On message send
Action: Send message
Message: "ğŸ” ENVIRONMENT CHECK - Before starting this task, please verify:

âœ… Python virtual environment is activated
âœ… All dependencies from requirements.txt are installed
âœ… Flask development server can start successfully
âœ… React development server can start successfully
âœ… All environment variables are properly configured
âœ… Database connections (if applicable) are working

If any of these checks fail, address them before proceeding with the task.

Run these commands to verify:
- `python --version` (should show Python 3.9+)
- `pip list` (check installed packages)
- `npm --version` (should show Node.js 16+)
- `npm list` (check frontend dependencies)

Proceed only when environment is confirmed working."
```

### 2. Code Quality Validation Hook

**Purpose**: Run quality checks after completing implementation tasks
**Trigger**: On agent execution complete
**Action**: Execute command

```
Hook Name: Code Quality Check
Trigger: On agent execution complete
Action: Execute command
Command:
echo "ğŸ” Running Code Quality Checks..."

# Python Backend Checks
if [ -d "backend" ]; then
  echo "ğŸ“‹ Checking Python code quality..."
  cd backend

  echo "  â†’ Running Black formatter check..."
  black --check --line-length 88 . || echo "âŒ Black formatting needed: run 'black --line-length 88 .'"

  echo "  â†’ Running Flake8 linting..."
  flake8 --max-line-length 88 --extend-ignore E203,W503 . || echo "âŒ Flake8 issues found"

  echo "  â†’ Running MyPy type checking..."
  mypy --strict . || echo "âŒ MyPy type issues found"

  echo "  â†’ Running pytest..."
  pytest --tb=short || echo "âŒ Tests failing"

  cd ..
fi

# Frontend Checks
if [ -d "frontend" ]; then
  echo "ğŸ“‹ Checking React code quality..."
  cd frontend

  echo "  â†’ Running ESLint..."
  npm run lint || echo "âŒ ESLint issues found: run 'npm run lint:fix'"

  echo "  â†’ Running TypeScript check..."
  npm run type-check || echo "âŒ TypeScript issues found"

  echo "  â†’ Running accessibility tests..."
  npm run test:a11y || echo "âŒ Accessibility issues found"

  cd ..
fi

echo "âœ… Code quality checks completed"
```

### 3. Accessibility Validation Hook

**Purpose**: Ensure accessibility standards when frontend files are modified
**Trigger**: On file save (_.tsx, _.jsx, _.ts, _.js files)
**Action**: Send message to agent

```
Hook Name: Accessibility Reminder
Trigger: On file save
File Pattern: *.tsx,*.jsx,*.ts,*.js
Action: Send message
Message: "â™¿ ACCESSIBILITY CHECK - Frontend component updated. Please ensure:

ğŸ·ï¸  **Labels & Forms**
   - All form inputs have proper labels (htmlFor attribute)
   - Required fields marked with aria-label='required'
   - Error messages use role='alert'

âŒ¨ï¸  **Keyboard Navigation**
   - All interactive elements are keyboard accessible
   - Focus indicators are visible and clear
   - Tab order is logical

ğŸ¨  **Visual Design**
   - Color contrast meets WCAG 2.1 AA standards (4.5:1 ratio)
   - Information not conveyed by color alone
   - Text is readable and scalable

ğŸ”Š  **Screen Readers**
   - ARIA labels used for complex components
   - Live regions for dynamic content (aria-live)
   - Proper heading hierarchy (h1 â†’ h2 â†’ h3)

ğŸ“Š  **Data & Charts**
   - Tables have proper headers and captions
   - Charts include alternative text descriptions
   - Progress indicators have ARIA attributes

ğŸ§ª  **Testing**
   Run: `npm run test:a11y` to validate accessibility compliance

Refer to the HTML Accessibility Guide for detailed examples."
```

### 4. Task Completion Validation Hook

**Purpose**: Validate task completion against requirements
**Trigger**: On agent execution complete
**Action**: Send message to agent

```
Hook Name: Task Completion Validation
Trigger: On agent execution complete
Action: Send message
Message: "âœ… TASK COMPLETION CHECKLIST

ğŸ“‹ **Code Quality**
   - [ ] Code follows Python PEP 8 standards (backend)
   - [ ] React components follow accessibility guidelines
   - [ ] All functions have proper type hints and docstrings
   - [ ] Error handling is implemented correctly

ğŸ§ª **Testing**
   - [ ] Unit tests written and passing
   - [ ] Property-based tests implemented (if applicable)
   - [ ] Integration tests cover main workflows
   - [ ] Accessibility tests pass

ğŸ“š **Documentation**
   - [ ] Code is self-documenting with clear variable names
   - [ ] Complex logic has explanatory comments
   - [ ] API endpoints documented (if applicable)

ğŸ”— **Requirements Traceability**
   - [ ] Task addresses specific requirements mentioned
   - [ ] All acceptance criteria are met
   - [ ] No scope creep beyond task definition

ğŸš€ **Integration**
   - [ ] Code integrates properly with existing components
   - [ ] No breaking changes to other parts of system
   - [ ] Database migrations (if applicable) are included

Mark this task as complete only when all items are verified."
```

### 5. ML Model Training Hook

**Purpose**: Specific checks for ML training tasks
**Trigger**: Manual (button click)
**Action**: Execute command

```
Hook Name: ML Training Validation
Trigger: Manual
Action: Execute command
Command:
echo "ğŸ¤– ML Training Environment Check..."

# Check Python ML dependencies
echo "ğŸ“¦ Checking ML dependencies..."
python -c "
import sys
required_packages = ['scikit-learn', 'pandas', 'numpy', 'matplotlib']
missing = []
for package in required_packages:
    try:
        __import__(package)
        print(f'âœ… {package} installed')
    except ImportError:
        missing.append(package)
        print(f'âŒ {package} missing')

if missing:
    print(f'Install missing packages: pip install {\" \".join(missing)}')
    sys.exit(1)
else:
    print('âœ… All ML dependencies available')
"

# Check dataset directory
if [ -d "datasets" ]; then
    echo "âœ… Dataset directory exists"
    echo "ğŸ“Š Available datasets:"
    ls -la datasets/
else
    echo "âŒ Dataset directory not found - create 'datasets' folder"
fi

# Check model storage
if [ -d "models" ]; then
    echo "âœ… Model storage directory exists"
else
    echo "ğŸ“ Creating model storage directory..."
    mkdir -p models
fi

# Verify training configuration
if [ -f "backend/config/training_config.py" ]; then
    echo "âœ… Training configuration found"
else
    echo "âŒ Training configuration missing"
fi

echo "ğŸ¯ ML environment check completed"
```

### 6. Deployment Readiness Hook

**Purpose**: Check if application is ready for deployment
**Trigger**: Manual (button click)
**Action**: Execute command

```
Hook Name: Deployment Readiness
Trigger: Manual
Action: Execute command
Command:
echo "ğŸš€ DEPLOYMENT READINESS CHECK"

# Security checks
echo "ğŸ”’ Security checks..."
echo "  â†’ Checking for hardcoded secrets..."
grep -r "password\|secret\|key\|token" --include="*.py" --include="*.js" --include="*.ts" --exclude-dir=node_modules --exclude-dir=.git . | grep -v "# Safe:" || echo "âœ… No obvious hardcoded secrets"

echo "  â†’ Checking for debug flags..."
grep -r "DEBUG.*=.*True\|console\.log\|print(" --include="*.py" --include="*.js" --include="*.ts" --exclude-dir=node_modules --exclude-dir=.git . || echo "âœ… No debug statements found"

# Environment checks
echo "ğŸŒ Environment checks..."
echo "  â†’ Checking for localhost references..."
grep -r "localhost\|127\.0\.0\.1" --exclude-dir=node_modules --exclude-dir=.git --exclude="*.md" . || echo "âœ… No hardcoded localhost URLs"

echo "  â†’ Checking environment variables..."
if [ -f ".env.example" ]; then
    echo "âœ… Environment template found"
else
    echo "âŒ Create .env.example with required variables"
fi

# Build tests
echo "ğŸ—ï¸  Build tests..."
if [ -d "backend" ]; then
    echo "  â†’ Testing backend startup..."
    cd backend
    timeout 10s python -c "from app import app; print('âœ… Backend imports successfully')" || echo "âŒ Backend startup issues"
    cd ..
fi

if [ -d "frontend" ]; then
    echo "  â†’ Testing frontend build..."
    cd frontend
    npm run build > /dev/null 2>&1 && echo "âœ… Frontend builds successfully" || echo "âŒ Frontend build issues"
    cd ..
fi

# Documentation check
echo "ğŸ“š Documentation check..."
[ -f "README.md" ] && echo "âœ… README.md exists" || echo "âŒ Create README.md"
[ -f "requirements.txt" ] && echo "âœ… requirements.txt exists" || echo "âŒ Create requirements.txt"
[ -f "package.json" ] && echo "âœ… package.json exists" || echo "âŒ Create package.json"

echo "ğŸ¯ Deployment readiness check completed"
```

### 7. Git Commit Quality Hook

**Purpose**: Ensure quality before commits
**Trigger**: Manual (before committing)
**Action**: Execute command

```
Hook Name: Pre-Commit Quality Check
Trigger: Manual
Action: Execute command
Command:
echo "ğŸ“ PRE-COMMIT QUALITY CHECK"

# Check git status
echo "ğŸ“Š Git status:"
git status --porcelain

# Run linting on staged files
echo "ğŸ” Checking staged Python files..."
git diff --cached --name-only --diff-filter=ACM | grep "\.py$" | xargs -r black --check --line-length 88
git diff --cached --name-only --diff-filter=ACM | grep "\.py$" | xargs -r flake8 --max-line-length 88

echo "ğŸ” Checking staged JavaScript/TypeScript files..."
git diff --cached --name-only --diff-filter=ACM | grep -E "\.(js|jsx|ts|tsx)$" | xargs -r npx eslint

# Check commit message format
echo "ğŸ’¬ Commit message guidelines:"
echo "  Format: type(scope): description"
echo "  Types: feat, fix, docs, style, refactor, test, chore"
echo "  Example: feat(dataset): add CSV upload validation"

# Run tests on staged files
echo "ğŸ§ª Running tests..."
if git diff --cached --name-only | grep -q "\.py$"; then
    echo "  â†’ Running Python tests..."
    pytest --tb=short
fi

if git diff --cached --name-only | grep -q -E "\.(js|jsx|ts|tsx)$"; then
    echo "  â†’ Running frontend tests..."
    cd frontend && npm test -- --watchAll=false && cd ..
fi

echo "âœ… Pre-commit checks completed"
echo "ğŸ’¡ If all checks pass, proceed with: git commit -m 'your message'"
```

## Hook Usage Guidelines

### When to Use Each Hook

1. **Environment Check** - Use at start of each development session
2. **Code Quality Check** - Automatically runs after task completion
3. **Accessibility Reminder** - Triggers when editing frontend components
4. **Task Completion Validation** - Use before marking tasks complete
5. **ML Training Validation** - Use before training models
6. **Deployment Readiness** - Use before deploying to staging/production
7. **Pre-Commit Quality** - Use before committing code to git

### Best Practices

- **Test hooks individually** after creating them
- **Modify commands** for your specific environment (Windows/Mac/Linux)
- **Add project-specific checks** as needed
- **Keep hook messages concise** but informative
- **Use emojis** for visual clarity in terminal output

### Troubleshooting

If hooks fail:

1. Check file paths are correct for your project structure
2. Ensure required tools are installed (black, flake8, mypy, etc.)
3. Verify shell commands work in your terminal
4. Adjust commands for your operating system

These hooks will significantly improve code quality and development workflow consistency for the ML Training Platform project.
